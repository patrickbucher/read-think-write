---
title: "The AI Control Group"
date: 2025-07-16T12:48:41+02:00
---

The iPhone was released back in 2007 and found wide adoptation quickly. We're talking about a magnitude of millions within a year. Since then, smartphones have been adopted in the magnitude of billions within less then twenty years. The adaptation of ChatGPT (and other AI tools that followed it) was even faster; we're talking about millions within _weeks_.

Toddlers can use iPhones, iPads as well as other smartphones and tablets without any substantial instruction. If those devices were harder to use, their adaptation would arguably have been much slower. The same is true for ChatGPT and the like, with a sligthly higher entrance hurdle: One needs to be capable of reading, writing, and typing. So toddlers are out, but adolescents are in.

I bought my first smartphone in 2013, roughly six years after they have been introduced, and I only did so because I was supposed to develop applications for those devices. By that time, I was already mildly annoyed by the usage patterns some people showed. For example, many people had the constant urge to _fact check_ (the term wasn't in wide use back then, as far as I can remember) almost everything unknown to them that came up during a conversation.

The early adopters didn't have any advantage whatsoever. The devices aren't hard to use, and most of the apps the early adopters spent a lot of time with had already become obsolete after a couple of years. So it was perfectly safe for me to wait buying and using a smartphone until I really saw some benefits (professionally, that was). Nowadays, having no smartphone is often almost infeasible, but I still admire people who can do without them.

This experience inculcated me with the realization that early adopters mostly just waste their time. So I didn't really care when ChatGPT was released to the public. Working as a software developer and as a teacher, I of course witnessed its effects rather quickly. But I didn't have any urge to jump on the train, for it certainly can't be hard to jump on it, especially when all of my students can use it (especially the weakest ones). Nowadays, even Notepad has AI functionality integrated, ready to render your notes into acceptable prose with a click or two.

This blog was inspired by Paul Graham's essay [Writes and Write-Nots](https://paulgraham.com/writes.html) (see my [initial post](#1) for details). Back then, I turned my ignorance into a concious decision: I won't be using AI tools, but do everything the old way. I wasn't eager to start using AI tools back then, but now came to the realization that my approach is perfectly rational.

When you run an experiment, say, to test a drug on people, you separate them into two groups: A treatment group and a control group. The treatment group gets the medicine, the control group only gets a placebo. After a while, the scientists running the experiment compare those two groups with one another. They not only check if the medicine had the intended effect, but also figure out if there were additional, unintended effects. If a large proportion of the treatment group shows those effects, but very few or nobody within the control group, then there's reason to believe that the medicine might be the culprit, which then needs to be verified in an additional experiment.

Having reached an adoptation of billions within a couple of years, there's almost nobody left in the control group for AI usage, at least not among the so-called "knowledge workers". Therefore, I conciusly place myself in the _AI Control Group_: I haven't been using AI tools for the last almost three years, and I won't adopt them within the near future. (Exceptions are: pasting my exam questions to AI prompts to check whether or not a student's answer came out of that particular AI.)

This is my long-term bet: I _suspect_ that people will be losing something crucial when delegating their tasks to AI. For example, the pressure to write well on one's own has been lifted by AI, so that everybody can produce acceptable prose by using those tools. But if deep and clear thinking requires phrasing things on your own, avoiding this crucial step of writing might detoriate one's thinking skills. I don't have a sound theory on the interrelation between thinking and writing—yet?—just a suspicion. But thanks to the control group mechanism, I don't need to: I just have to wait and see. I might lose a little in the meantime in terms of productivity, but the thought of being an ultra-late adapter somewhere in the future doesn't scare me at all.

I'm aware that this is not a perfectly designed experiment, because I know that I'm part of the control group and won't receive any AI placebo. I even adjust my behaviour conciously against what the AI enthusiasts do: I read more on paper, picked up writing longhand, and even do things widely considered inefficient and reactionary, e.g. summarizing Fyodor Dostoevskys _Brothers Karamazov_ chapter by chapter—by reading every chapter twice before I summarize it longhand while reading that chapter for the third time, and, finally, typing my hand-written notes in a command-line text editor, out of which I generate a [nice PDF](https://raw.githubusercontent.com/patrickbucher/books/refs/heads/master/dostojewskij_brueder-karamasow.pdf). However, I consider this experiment still worthwhile, and I'll probably be observing some interesting effects.

I wonder if there'll also be a control group of younger people (say, 16 to 20 year old students I encounter in my work as a teacher). I know that there's a rather small control group of students with tight restrictions on their technology use up to the age of 16. (Those students usually are not only more knowledgable, but also more focused, and work harder than the others; they also often show superiour social skills. Missing out on social networks turns out to be rather beneficial for their social skills in their case.) Probably those students can only be found among schools that use no digital technology at all, which of course has a confounding effect: Is it just computers, or is it AI that accounts for the observed effect?

I'll write more on my observations on the _AI Treatment Group_ from the perspective of the _AI Control Group_ in forthcoming posts. (I'll pick up my copy of Lev Vygotsky's _Thought and Language_ now, which hopefully gives me more insight on the theoretical side of my initial question on the interrelation of thinking and writing. I'd like to write more on that, too.)

To summarize: I won't be using AI tools for the next couple of years. Not because I know what they're doing to us, but because I _don't know_ but only _suspect_ that they'll be having some effect on us we _cannot_ fathom yet.

